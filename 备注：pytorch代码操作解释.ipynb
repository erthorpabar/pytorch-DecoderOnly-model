{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available()) # 是否可以用cuda\n",
    "print(torch.cuda.is_bf16_supported()) # 是否可以用bf16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "dataclass用法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "<class 'type'>\n"
     ]
    }
   ],
   "source": [
    "# 定义参数\n",
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class arg:\n",
    "    x: int = 2\n",
    "    y: int = 4\n",
    "\n",
    "print(arg.x)\n",
    "print(type(arg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "矩阵对位相乘和行列相乘的几何意义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "对位相乘：\n",
      " tensor([[ 5, 12],\n",
      "        [21, 32]])\n",
      "对位相乘：\n",
      " tensor([[ 5, 12],\n",
      "        [21, 32]])\n",
      "行列相乘：几何意义为将向量进行旋转拉伸\n",
      " tensor([[19, 22],\n",
      "        [43, 50]])\n",
      "行列相乘：几何意义为将向量进行旋转拉伸\n",
      " tensor([[19, 22],\n",
      "        [43, 50]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "A = torch.tensor([[1, 2],\n",
    "                  [3, 4]])\n",
    "\n",
    "B = torch.tensor([[5, 6],\n",
    "                  [7, 8]])\n",
    "\n",
    "print('对位相乘：\\n',torch.mul(A, B))\n",
    "print('对位相乘：\\n',A * B)\n",
    "\n",
    "print('行列相乘：几何意义为将向量进行旋转拉伸\\n',torch.matmul(A, B))\n",
    "print('行列相乘：几何意义为将向量进行旋转拉伸\\n',A @ B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "判断矩阵形状的两种方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 4])\n",
      "torch.Size([2, 3, 4])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "a = torch.zeros(2,3,4)\n",
    "print(a.shape)\n",
    "print(a.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "embedding权重"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 300])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# 输入\n",
    "input = torch.LongTensor([1, 2, 5, 4])\n",
    "\n",
    "# 构建权重\n",
    "vocab_size = 10000 # 词表大小\n",
    "embedding_dim = 300 # 映射维度\n",
    "embedding_weights = nn.Embedding(vocab_size, embedding_dim)\n",
    "\n",
    "# 输出\n",
    "embeddings = embedding_weights(input)\n",
    "\n",
    "# embedding作用\n",
    "'''\n",
    "vocab_size代表有多少种不同的个体\n",
    "从而为每一个个体设置了一个n个维度的向量数值，代表他们的意义或标签\n",
    "从而增加一个维度\n",
    "'''\n",
    "print(embeddings.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "linear权重"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "线性层的形状: torch.Size([3, 5])\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "只对矩阵最后一个维度进行计算\n",
    "\n",
    "Linear：生成线性y=wx+b权重参数的方法\n",
    "\n",
    "行 代表有多少个线性方程\n",
    "列 代表有多少个x输出\n",
    "'''\n",
    "# (5个输入，3个输出)\n",
    "# (3行，5列)\n",
    "# 举例子：(3,5) @ (5).T = (3)\n",
    "linear = nn.Linear(5,3)\n",
    "print('线性层的形状:',linear.weight.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "unsqueeze增加维度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "原始矩阵：\n",
      " tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n",
      "第一个维度左边增加：\n",
      " tensor([[[0., 0., 0.],\n",
      "         [0., 0., 0.]]])\n",
      "第二个维度左边增加：\n",
      " tensor([[[0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0.]]])\n",
      "第三个维度左边增加：\n",
      " tensor([[[0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.]]])\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "什么是unsqueeze(x)？\n",
    "-> 在x之前增加一个维度，作为新的维度。\n",
    "-> 这会改变原始矩阵的形状，\n",
    "原始矩阵a(2,3) 2行，3列\n",
    "a.unsqueeze(0) -> (1,2,3) 1个，2行，3列\n",
    "a.unsqueeze(1) -> (2,1,3) 2个，1行，3列\n",
    "a.unsqueeze(2) -> (2,3,1) 2个，3行，1列\n",
    "\n",
    "最后两个参数永远被解读为 行，列\n",
    "前边的参数永远被优先解读为 分组，个数，批量 等概念\n",
    "'''\n",
    "a=torch.zeros(2,3)\n",
    "print('原始矩阵：\\n',a)\n",
    "print('第一个维度左边增加：\\n',a.unsqueeze(0)) # (1,2,3)\n",
    "print('第二个维度左边增加：\\n',a.unsqueeze(1)) # (2,1,3)\n",
    "print('第三个维度左边增加：\\n',a.unsqueeze(2)) # (2,3,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "交换矩阵维度：transpose，permute两种方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 4])\n",
      "torch.Size([2, 4, 3])\n",
      "torch.Size([3, 2, 4])\n"
     ]
    }
   ],
   "source": [
    "a = torch.zeros(2,3,4)\n",
    "print(a.shape)\n",
    "\n",
    "# permute 方法交换维度\n",
    "b = a.permute(0,2,1)\n",
    "print(b.shape)\n",
    "\n",
    "# transpose 方法交换维度\n",
    "c = a.transpose(0,1)\n",
    "print(c.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "改变矩阵形状：reshape，view两种方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 4])\n",
      "torch.Size([6, 4])\n",
      "torch.Size([6, 4])\n"
     ]
    }
   ],
   "source": [
    "a = torch.zeros(2,3,4)\n",
    "print(a.shape)\n",
    "\n",
    "b = a.reshape(6,4)\n",
    "print(b.shape)\n",
    "\n",
    "c = a.view(6,4)\n",
    "print(b.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "ModuleDict保存模型参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.nn.modules.container.ModuleDict'>\n",
      "Linear(in_features=4, out_features=2, bias=True)\n",
      "tensor([[ 0.5797,  0.3375,  0.1751,  0.5144, -0.1534]],\n",
      "       grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# 把模型用字典的形式保存起来\n",
    "import torch.nn as nn\n",
    "\n",
    "model = nn.ModuleDict(dict(\n",
    "    a = nn.Linear(4, 2),\n",
    "    b = nn.Linear(2, 5),\n",
    "))\n",
    "print(type(model))\n",
    "print(model.a)\n",
    "\n",
    "# 输入\n",
    "input = torch.randn(1, 4)\n",
    "\n",
    "# 顺序运算\n",
    "output = input\n",
    "for model,layer in model.items():\n",
    "    output = layer(output)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "ModuleList保存模型参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.nn.modules.container.ModuleList'>\n",
      "tensor([[ 0.3161,  0.1486, -0.5677, -0.6741, -0.4152]],\n",
      "       grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "model = nn.ModuleList([\n",
    "    nn.Linear(4,2),\n",
    "    nn.Linear(2,5),\n",
    "])\n",
    "print(type(model))\n",
    "\n",
    "# 输入\n",
    "input = torch.randn(1, 4)\n",
    "\n",
    "# 顺序运算\n",
    "output = input\n",
    "for layer in model:\n",
    "    output = layer(output)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Sequential保存模型参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.nn.modules.container.Sequential'>\n",
      "tensor([[ 0.4346, -0.0176]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(10, 5),  # 输入层到隐藏层\n",
    "    nn.ReLU(),         # 激活函数\n",
    "    nn.Linear(5, 2)    # 隐藏层到输出层\n",
    ")\n",
    "print(type(model))\n",
    "\n",
    "# 输入\n",
    "input = torch.randn(1, 10)\n",
    "\n",
    "# 运算\n",
    "output = model(input)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "isinstance判断类别属性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 定义一个类\n",
    "class a:\n",
    "    pass\n",
    "\n",
    "# 实例化的类\n",
    "obj = a()\n",
    "\n",
    "# 判断是否是某个类别\n",
    "result = isinstance(obj, a)\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
